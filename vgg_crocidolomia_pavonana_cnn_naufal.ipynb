{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Library"
      ],
      "metadata": {
        "id": "9U9T4iHZ0M9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYrVZJhIDhVj",
        "outputId": "c797bd91-440d-4fa1-cda6-48e34e9226b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modules loaded\n"
          ]
        }
      ],
      "source": [
        "# import system libs\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools\n",
        "\n",
        "# import data handling tools\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# import Deep learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Gradcam support tools\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto( intra_op_parallelism_threads=1, inter_op_parallelism_threads=1 )\n",
        "sess = tf.compat.v1.Session( graph=tf.compat.v1.get_default_graph(), config=session_conf )\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "1u3S-uw2DvJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ],
      "metadata": {
        "id": "a0p467IiF-Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baca API Kaggle & dataset dari kaggle\n"
      ],
      "metadata": {
        "id": "H5-upiy90Up9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "#liat kaggle.json nya dari sini fi : https://www.kaggle.com/settings/account terus pilih API-create new token"
      ],
      "metadata": {
        "id": "U2lPKHMnGB8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "EGTMeuwPGcWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcTdrYMyGf2K",
        "outputId": "d142d3b5-4056-4402-85a7-df2cc854e3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "\n",
        "# Replace 'username/dataset' with the actual Kaggle dataset you want to download\n",
        "dataset_name = 'rizqiakbarr13/larva-bit-to-high'\n",
        "\n",
        "# Authenticate with Kaggle API\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "# Download the dataset\n",
        "kaggle.api.dataset_download_files(dataset_name, unzip=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdoC_bsdGi2N",
        "outputId": "10ae7ac1-cf94-494c-d759-d783cc36c592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Membaca directory dari dataset nya"
      ],
      "metadata": {
        "id": "vkb1Sf1L01BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = r'/content/larva'"
      ],
      "metadata": {
        "id": "huB9lntBEUmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membaca path data"
      ],
      "metadata": {
        "id": "9UuB7-UsFjU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data paths with labels\n",
        "def define_paths(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "\n",
        "    folds = os.listdir(data_dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(data_dir, fold)\n",
        "\n",
        "        # check the folders from main directory. If there are another files, ignore them\n",
        "        if pathlib.Path(foldpath).suffix != '':\n",
        "            continue\n",
        "\n",
        "        filelist = os.listdir(foldpath)\n",
        "\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "\n",
        "    return filepaths, labels"
      ],
      "metadata": {
        "id": "UhB9c54WFigD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Menyimpan path dalam dataframe"
      ],
      "metadata": {
        "id": "htrWUYynGMgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )\n",
        "def define_df(files, classes):\n",
        "    Fseries = pd.Series(files, name= 'filepaths')\n",
        "    Lseries = pd.Series(classes, name='labels')\n",
        "    return pd.concat([Fseries, Lseries], axis= 1)"
      ],
      "metadata": {
        "id": "WoSh949yGHz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files, classes = define_paths(data_dir)\n",
        "df = define_df(files, classes)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "iYvmO9cFGP2t",
        "outputId": "4befd8b8-294b-473a-b73e-c6e2eec37108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       filepaths   labels\n",
              "0  /content/larva/INSTAR4/images  INSTAR4\n",
              "1  /content/larva/INSTAR3/images  INSTAR3\n",
              "2  /content/larva/INSTAR1/images  INSTAR1\n",
              "3  /content/larva/INSTAR2/images  INSTAR2"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5f609146-52cb-422a-bd7f-532db4a2315e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/larva/INSTAR4/images</td>\n",
              "      <td>INSTAR4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/larva/INSTAR3/images</td>\n",
              "      <td>INSTAR3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/larva/INSTAR1/images</td>\n",
              "      <td>INSTAR1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/larva/INSTAR2/images</td>\n",
              "      <td>INSTAR2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f609146-52cb-422a-bd7f-532db4a2315e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e6b1e79e-7325-4468-a991-e3639625d8cf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6b1e79e-7325-4468-a991-e3639625d8cf')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e6b1e79e-7325-4468-a991-e3639625d8cf button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f609146-52cb-422a-bd7f-532db4a2315e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f609146-52cb-422a-bd7f-532db4a2315e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWN8ZcoJOgkM",
        "outputId": "6af35526-8453-4148-8eeb-12c494bc822a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   filepaths  4 non-null      object\n",
            " 1   labels     4 non-null      object\n",
            "dtypes: object(2)\n",
            "memory usage: 192.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.labels.value_counts()"
      ],
      "metadata": {
        "id": "0IOrhE8oGRYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5679237-4250-4357-f402-7a97a3ed6c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "INSTAR4    1\n",
              "INSTAR3    1\n",
              "INSTAR1    1\n",
              "INSTAR2    1\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membagi data (train, validation, test)"
      ],
      "metadata": {
        "id": "xOY5OPqZYs4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory_path = '/content/train_data'\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "else:\n",
        "    print(f\"The directory '{directory_path}' already exists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLdeeSLwD32b",
        "outputId": "8e0aff4b-78fb-42ba-eb0f-7d8aa8d9eaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The directory '/content/train_data' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Tentukan path dataset,lu buat pathh di rectory nya di folder content\n",
        "data_dir = '/content/larva/INSTAR3/images'\n",
        "\n",
        "# Daftar nama kelas (misalnya: 'kelas_1', 'kelas_2', dst.)\n",
        "class_names = os.listdir(data_dir)\n",
        "\n",
        "# Persentase pembagian data (misal: 70% train, 15% validation, 15% test)\n",
        "train_split = 0.7\n",
        "val_split = 0.15\n",
        "test_split = 0.15\n",
        "\n",
        "# List semua file dalam direktori data\n",
        "file_list = os.listdir(data_dir)\n",
        "\n",
        "# Mengacak urutan file\n",
        "random.shuffle(file_list)\n",
        "\n",
        "# Hitung jumlah file untuk setiap bagian\n",
        "total_files = len(file_list)\n",
        "train_count = int(total_files * train_split)\n",
        "val_count = int(total_files * val_split)\n",
        "\n",
        "# Memisahkan file menjadi train, validation, dan test\n",
        "train_files = file_list[:train_count]\n",
        "val_files = file_list[train_count:train_count + val_count]\n",
        "test_files = file_list[train_count + val_count:]\n",
        "\n",
        "# Membuat direktori baru jika belum ada\n",
        "#bikin file train_dir, val_dir dan test_dir di folder content fi\n",
        "train_dir = '/content/train_dir'\n",
        "val_dir = '/content/val_dir'\n",
        "test_dir = '/content/test_dir'\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Memindahkan file ke direktori masing-masing\n",
        "def move_files(files, source_dir, dest_dir):\n",
        "    for file in files:\n",
        "        src_path = os.path.join(source_dir, file)\n",
        "        dest_path = os.path.join(dest_dir, file)\n",
        "        shutil.move(src_path, dest_path)\n",
        "\n",
        "move_files(train_files, data_dir, train_dir)\n",
        "move_files(val_files, data_dir, val_dir)\n",
        "move_files(test_files, data_dir, test_dir)\n",
        "\n",
        "print(\"Data telah berhasil dibagi menjadi train, validation, dan test.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOcLcEf4o75y",
        "outputId": "98ac5885-4f82-4d2e-dd95-57f927389341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data telah berhasil dibagi menjadi train, validation, dan test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Diasumsikan Anda sudah mendefinisikan train_dir, valid_dir, dan test_dir\n",
        "\n",
        "# Membuat instance ImageDataGenerator untuk data train, validasi, dan test\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Menyiapkan generator menggunakan flow_from_directory\n",
        "batch_size = 32\n",
        "image_height = 150\n",
        "image_width = 150\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Periksa panjang generator\n",
        "print(\"Train Generator Length:\", len(train_generator))\n",
        "print(\"Validation Generator Length:\", len(valid_generator))\n",
        "print(\"Test Generator Length:\", len(test_generator))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT8l_iiPIFrU",
        "outputId": "47224437-d727-42e7-811c-3a993323d7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Train Generator Length: 0\n",
            "Validation Generator Length: 0\n",
            "Test Generator Length: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zvcFNOB9Kws",
        "outputId": "853e67da-55e9-480a-c330-127d876d57cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Tentukan direktori tempat gambar-gambar Anda disimpan\n",
        "data_directory = '/content/larva/INSTAR1/images/'\n",
        "\n",
        "# Inisialisasi list untuk menyimpan data gambar dan label\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Loop melalui setiap gambar dalam direktori data\n",
        "for image_file in os.listdir(data_directory):\n",
        "    # Baca gambar dari direktori\n",
        "    image_path = os.path.join(data_directory, image_file)\n",
        "    image = load_img(image_path, target_size=(224, 224))  # Ubah ukuran gambar jika diperlukan\n",
        "    image_array = img_to_array(image)\n",
        "    X.append(image_array)\n",
        "\n",
        "    # Encode label kelas\n",
        "    # Jika nama gambar mengandung label, Anda bisa ekstrak label dari nama file.\n",
        "    # Misalnya, jika nama file adalah 'cat001.jpg', labelnya adalah 'cat'.\n",
        "    label = image_file.split('.')[0]  # Mengambil bagian sebelum ekstensi file (labelnya)\n",
        "    y.append(label)\n",
        "\n",
        "# Ubah list ke dalam array NumPy\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Normalisasi gambar ke dalam rentang 0-1\n",
        "X = X / 255.0\n",
        "\n",
        "# Encode label ke dalam bentuk angka menggunakan one-hot encoding\n",
        "# Jika Anda sudah memiliki label dalam bentuk angka, Anda bisa melewati langkah ini\n",
        "unique_labels = np.unique(y)\n",
        "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
        "y_encoded = np.array([label_to_index[label] for label in y])\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "\n",
        "# Sekarang, Anda memiliki data `X` (gambar) dan `y_encoded` (label) siap untuk digunakan dalam model computer vision.\n",
        "\n"
      ],
      "metadata": {
        "id": "j1c6eb-W7oTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Misalkan X adalah data fitur dan y adalah label/target\n",
        "\n",
        "# Bagi data menjadi data latih (train) dan data uji (test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Buat instance StratifiedKFold dengan n_splits yang lebih rendah (misalnya, 3 lipatan)\n",
        "n_splits = 2\n",
        "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Inisialisasi list untuk menyimpan hasil akurasi dari setiap lipatan\n",
        "fold_accuracies = []\n",
        "\n",
        "# Lakukan validasi silang\n",
        "for train_index, val_index in stratkf.split(X_train, y_train):\n",
        "    # Bagi data latih dan validasi berdasarkan indeks yang dihasilkan oleh StratifiedKFold\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Lakukan pelatihan model pada data latih (X_train_fold, y_train_fold)\n",
        "    # Evaluasi model pada data validasi (X_val_fold, y_val_fold)\n",
        "    # Simpan akurasi dari setiap lipatan ke dalam list fold_accuracies\n",
        "\n",
        "# Setelah selesai validasi silang, hitung rata-rata akurasi dari semua lipatan\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "\n",
        "# Latih model final dengan data latih dan uji\n",
        "# Evaluasi model pada data uji (X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "SfKVr2Wo60eW",
        "outputId": "37fe9c36-6253-4988-d0e5-26becf5bc5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-f0fe64456434>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Buat instance StratifiedKFold dengan n_splits yang lebih rendah (misalnya, 3 lipatan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mstratkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Inisialisasi list untuk menyimpan hasil akurasi dari setiap lipatan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    299\u001b[0m                 \u001b[0;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strat = df['labels']\n",
        "train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n",
        "\n",
        "# valid and test dataframe\n",
        "strat = dummy_df['labels']\n",
        "valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123, stratify= strat)"
      ],
      "metadata": {
        "id": "tzn9knyULNpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dir.labels.value_counts())\n",
        "print(valid_dir.labels.value_counts())\n",
        "print(test_dir.labels.value_counts())"
      ],
      "metadata": {
        "id": "1XPANiZ8YnQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-proses load data\n",
        "### penentuan parameter data generator"
      ],
      "metadata": {
        "id": "pL4SQOjsYu1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model parameters\n",
        "img_size = (256, 256)\n",
        "channels = 3 # either BGR or Grayscale\n",
        "color = 'rgb'\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "# Recommended : use custom function for test data batch size, else we can use normal batch size.\n",
        "# mencari faktor dari jumlah test set yang kurang dari sama dengan 80\n",
        "ts_length = len(test_dir)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size"
      ],
      "metadata": {
        "id": "cS8rmxcWYoK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch_size"
      ],
      "metadata": {
        "id": "5iD0H6WUY1zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80])"
      ],
      "metadata": {
        "id": "GjwIi3P5Y24k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_steps"
      ],
      "metadata": {
        "id": "RNYe1bU7Y3xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Generator"
      ],
      "metadata": {
        "id": "Nvw5PrlqZBji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train and validation batch size\n",
        "batch_size = 64\n",
        "\n",
        "# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n",
        "def scalar(img):\n",
        "    return img\n",
        "\n",
        "tr_gen = ImageDataGenerator(preprocessing_function= scalar,\n",
        "                            rescale=1./255,\n",
        "                            zoom_range=0.5,\n",
        "                            rotation_range=10,\n",
        "                            horizontal_flip=True,\n",
        "                            shear_range=0.2,\n",
        "                            fill_mode='nearest')\n",
        "ts_gen = ImageDataGenerator(preprocessing_function= scalar, rescale=1./255)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe( train_dir, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= color, shuffle= True, batch_size= batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe( valid_dir, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= color, shuffle= True, batch_size= batch_size)\n",
        "\n",
        "# Note: we will use custom test_batch_size, and make shuffle= false\n",
        "test_gen = ts_gen.flow_from_dataframe( test_dir, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= color, shuffle= False, batch_size= test_batch_size)"
      ],
      "metadata": {
        "id": "AORjV6WtY46z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(gen):\n",
        "    '''\n",
        "    This function take the data generator and show sample of the images\n",
        "    '''\n",
        "\n",
        "    # return classes , images to be displayed\n",
        "    g_dict = gen.class_indices        # defines dictionary {'class': index}\n",
        "    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string\n",
        "    images, labels = next(gen)        # get a batch size samples from the generator\n",
        "\n",
        "    # calculate number of displayed samples\n",
        "    length = len(labels)        # length of batch size\n",
        "    sample = min(length, 25)    # check if sample less than 25 images\n",
        "\n",
        "    plt.figure(figsize= (20, 20))\n",
        "\n",
        "    for i in range(sample):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        image = images[i] #/ 255       # scales data to range (0 - 255)\n",
        "        plt.imshow(image)\n",
        "        index = np.argmax(labels[i])  # get image index\n",
        "        class_name = classes[index]   # get class of image\n",
        "        plt.title(class_name, color= 'blue', fontsize= 12)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tRcHk0ROZVfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_gen)"
      ],
      "metadata": {
        "id": "nZHOwh93ZaA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(valid_gen)"
      ],
      "metadata": {
        "id": "gIgn8P8YZbPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(test_gen)"
      ],
      "metadata": {
        "id": "ySAqqDZ9ZsID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pengaturan Training Model\n",
        "### Callback"
      ],
      "metadata": {
        "id": "qwMqf73FaJIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n",
        "        super(MyCallback, self).__init__()\n",
        "        self.model = model\n",
        "        self.patience = patience # specifies how many epochs without improvement before learning rate is adjusted\n",
        "        self.stop_patience = stop_patience # specifies how many times to adjust lr without improvement to stop training\n",
        "        self.threshold = threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n",
        "        self.factor = factor # factor by which to reduce the learning rate\n",
        "        self.batches = batches # number of training batch to run per epoch\n",
        "        self.epochs = epochs\n",
        "        self.ask_epoch = ask_epoch\n",
        "        self.ask_epoch_initial = ask_epoch # save this value to restore if restarting training\n",
        "\n",
        "        # callback variables\n",
        "        self.count = 0 # how many times lr has been reduced without improvement\n",
        "        self.stop_count = 0\n",
        "        self.best_epoch = 1   # epoch with the lowest loss\n",
        "        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initial learning rate and save it\n",
        "        self.highest_tracc = 0.0 # set highest training accuracy to 0 initially\n",
        "        self.lowest_vloss = np.inf # set lowest validation loss to infinity initially\n",
        "        self.best_weights = self.model.get_weights() # set best weights to model's initial weights\n",
        "        self.initial_weights = self.model.get_weights()   # save initial weights if they have to get restored\n",
        "\n",
        "    # Define a function that will run when train begins\n",
        "    def on_train_begin(self, logs= None):\n",
        "        msg = 'Do you want model asks you to halt the training [y/n] ?'\n",
        "        print(msg)\n",
        "        ans = input('')\n",
        "        if ans in ['Y', 'y']:\n",
        "            self.ask_permission = 1\n",
        "        elif ans in ['N', 'n']:\n",
        "            self.ask_permission = 0\n",
        "\n",
        "        msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n",
        "        print(msg)\n",
        "        self.start_time = time.time()\n",
        "\n",
        "\n",
        "    def on_train_end(self, logs= None):\n",
        "        stop_time = time.time()\n",
        "        tr_duration = stop_time - self.start_time\n",
        "        hours = tr_duration // 3600\n",
        "        minutes = (tr_duration - (hours * 3600)) // 60\n",
        "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
        "\n",
        "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
        "        print(msg)\n",
        "\n",
        "        # set the weights of the model to the best weights\n",
        "        self.model.set_weights(self.best_weights)\n",
        "\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs= None):\n",
        "        # get batch accuracy and loss\n",
        "        acc = logs.get('accuracy') * 100\n",
        "        loss = logs.get('loss')\n",
        "\n",
        "        # prints over on the same line to show running batch count\n",
        "        msg = '{0:20s}processing batch {1:} of {2:5s}-   accuracy=  {3:5.3f}   -   loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n",
        "        print(msg, '\\r', end= '')\n",
        "\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs= None):\n",
        "        self.ep_start = time.time()\n",
        "\n",
        "\n",
        "    # Define method runs on the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs= None):\n",
        "        ep_end = time.time()\n",
        "        duration = ep_end - self.ep_start\n",
        "\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
        "        current_lr = lr\n",
        "        acc = logs.get('accuracy')  # get training accuracy\n",
        "        v_acc = logs.get('val_accuracy')  # get validation accuracy\n",
        "        loss = logs.get('loss')  # get training loss for this epoch\n",
        "        v_loss = logs.get('val_loss')  # get the validation loss for this epoch\n",
        "\n",
        "        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n",
        "            monitor = 'accuracy'\n",
        "            if epoch == 0:\n",
        "                pimprov = 0.0\n",
        "            else:\n",
        "                pimprov = (acc - self.highest_tracc ) * 100 / self.highest_tracc # define improvement of model progres\n",
        "\n",
        "            if acc > self.highest_tracc: # training accuracy improved in the epoch\n",
        "                self.highest_tracc = acc # set new highest training accuracy\n",
        "                self.best_weights = self.model.get_weights() # training accuracy improved so save the weights\n",
        "                self.count = 0 # set count to 0 since training accuracy improved\n",
        "                self.stop_count = 0 # set stop counter to 0\n",
        "                if v_loss < self.lowest_vloss:\n",
        "                    self.lowest_vloss = v_loss\n",
        "                self.best_epoch = epoch + 1  # set the value of best epoch for this epoch\n",
        "\n",
        "            else:\n",
        "                # training accuracy did not improve check if this has happened for patience number of epochs\n",
        "                # if so adjust learning rate\n",
        "                if self.count >= self.patience - 1: # lr should be adjusted\n",
        "                    lr = lr * self.factor # adjust the learning by factor\n",
        "                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n",
        "                    self.count = 0 # reset the count to 0\n",
        "                    self.stop_count = self.stop_count + 1 # count the number of consecutive lr adjustments\n",
        "                    self.count = 0 # reset counter\n",
        "                    if v_loss < self.lowest_vloss:\n",
        "                        self.lowest_vloss = v_loss\n",
        "                else:\n",
        "                    self.count = self.count + 1 # increment patience counter\n",
        "\n",
        "        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n",
        "            monitor = 'val_loss'\n",
        "            if epoch == 0:\n",
        "                pimprov = 0.0\n",
        "\n",
        "            else:\n",
        "                pimprov = (self.lowest_vloss - v_loss ) * 100 / self.lowest_vloss\n",
        "\n",
        "            if v_loss < self.lowest_vloss: # check if the validation loss improved\n",
        "                self.lowest_vloss = v_loss # replace lowest validation loss with new validation loss\n",
        "                self.best_weights = self.model.get_weights() # validation loss improved so save the weights\n",
        "                self.count = 0 # reset count since validation loss improved\n",
        "                self.stop_count = 0\n",
        "                self.best_epoch = epoch + 1 # set the value of the best epoch to this epoch\n",
        "\n",
        "            else: # validation loss did not improve\n",
        "                if self.count >= self.patience - 1: # need to adjust lr\n",
        "                    lr = lr * self.factor # adjust the learning rate\n",
        "                    self.stop_count = self.stop_count + 1 # increment stop counter because lr was adjusted\n",
        "                    self.count = 0 # reset counter\n",
        "                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n",
        "\n",
        "                else:\n",
        "                    self.count = self.count + 1 # increment the patience counter\n",
        "\n",
        "                if acc > self.highest_tracc:\n",
        "                    self.highest_tracc = acc\n",
        "\n",
        "        msg = f'{str(epoch + 1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc * 100:^9.3f}{v_loss:^9.5f}{v_acc * 100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n",
        "        print(msg)\n",
        "\n",
        "        if self.stop_count > self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n",
        "            msg = f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n",
        "            print(msg)\n",
        "            self.model.stop_training = True # stop training\n",
        "\n",
        "        else:\n",
        "            if self.ask_epoch != None and self.ask_permission != 0:\n",
        "                if epoch + 1 >= self.ask_epoch:\n",
        "                    msg = 'enter H to halt training or an integer for number of epochs to run then ask again'\n",
        "                    print(msg)\n",
        "\n",
        "                    ans = input('')\n",
        "                    if ans == 'H' or ans == 'h':\n",
        "                        msg = f'training has been halted at epoch {epoch + 1} due to user input'\n",
        "                        print(msg)\n",
        "                        self.model.stop_training = True # stop training\n",
        "\n",
        "                    else:\n",
        "                        try:\n",
        "                            ans = int(ans)\n",
        "                            self.ask_epoch += ans\n",
        "                            msg = f' training will continue until epoch {str(self.ask_epoch)}'\n",
        "                            print(msg)\n",
        "                            msg = '{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss', 'V_acc', 'LR', 'Next LR', 'Monitor', '% Improv', 'Duration')\n",
        "                            print(msg)\n",
        "\n",
        "                        except Exception:\n",
        "                            print('Invalid')"
      ],
      "metadata": {
        "id": "K16vKMyLZtl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(hist):\n",
        "    '''\n",
        "    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n",
        "    '''\n",
        "\n",
        "    # Define needed variables\n",
        "    tr_acc = hist.history['accuracy']\n",
        "    tr_loss = hist.history['loss']\n",
        "    val_acc = hist.history['val_accuracy']\n",
        "    val_loss = hist.history['val_loss']\n",
        "    index_loss = np.argmin(val_loss)\n",
        "    val_lowest = val_loss[index_loss]\n",
        "    index_acc = np.argmax(val_acc)\n",
        "    acc_highest = val_acc[index_acc]\n",
        "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize= (20, 8))\n",
        "    plt.style.use('fivethirtyeight')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "39zY2iPMaMiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n",
        "\t'''\n",
        "\tThis function plot confusion matrix method from sklearn package.\n",
        "\t'''\n",
        "\n",
        "\tplt.figure(figsize= (10, 10))\n",
        "\tplt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n",
        "\tplt.title(title)\n",
        "\tplt.colorbar()\n",
        "\n",
        "\ttick_marks = np.arange(len(classes))\n",
        "\tplt.xticks(tick_marks, classes, rotation= 45)\n",
        "\tplt.yticks(tick_marks, classes)\n",
        "\n",
        "\tif normalize:\n",
        "\t\tcm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n",
        "\t\tprint('Normalized Confusion Matrix')\n",
        "\n",
        "\telse:\n",
        "\t\tprint('Confusion Matrix, Without Normalization')\n",
        "\n",
        "\tprint(cm)\n",
        "\n",
        "\tthresh = cm.max() / 2.\n",
        "\tfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "\t\tplt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "\tplt.tight_layout()\n",
        "\tplt.ylabel('True Label')\n",
        "\tplt.xlabel('Predicted Label')"
      ],
      "metadata": {
        "id": "uN7i8EzNaOqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model using Functional API\n",
        "### Model VGG19 (untuk fine tuning)"
      ],
      "metadata": {
        "id": "4fHCExHNaVfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Structure\n",
        "img_size = (256, 256)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n",
        "\n",
        "# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n",
        "# we will use efficientnetb3 from EfficientNet family.\n",
        "base_model = tf.keras.applications.vgg19.VGG19(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n",
        "\n",
        "# additional layer\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "outputs = Dense(class_count, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, outputs)\n",
        "\n",
        "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n"
      ],
      "metadata": {
        "id": "sha4IO2xaPui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "CkdfS4UpaaGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Functional API Model"
      ],
      "metadata": {
        "id": "T3Y8o4zbbBZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HyperParameter untuk training model"
      ],
      "metadata": {
        "id": "MhoQ5atcbC0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64   # set batch size for training\n",
        "epochs = 100   # number of all epochs in training\n",
        "patience = 3   #number of epochs to wait to adjust lr if monitored value does not improve\n",
        "stop_patience = 10   # number of epochs to wait before stopping training if monitored value does not improve\n",
        "threshold = 0.9   # if train accuracy is < threshold adjust monitor accuracy, else monitor validation loss\n",
        "factor = 0.5   # factor to reduce lr by\n",
        "ask_epoch = 5   # number of epochs to run before asking if you want to halt training\n",
        "batches = int(np.ceil(len(train_gen.labels) / batch_size))    # number of training batch to run per epoch\n",
        "\n",
        "callbacks = [MyCallback(model= model, patience= patience, stop_patience= stop_patience, threshold= threshold,\n",
        "            factor= factor, batches= batches, epochs= epochs, ask_epoch= ask_epoch )]"
      ],
      "metadata": {
        "id": "JkIFOxgWa49m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x= train_gen, epochs= epochs, verbose= 0, callbacks= callbacks,\n",
        "                    validation_data= valid_gen, validation_steps= None, shuffle= False)"
      ],
      "metadata": {
        "id": "r5JoFo4FbIVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## graphic plotting"
      ],
      "metadata": {
        "id": "zwfx0dwbAK_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training(history)"
      ],
      "metadata": {
        "id": "B5e321YNbJ6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluasi Model (train_df, valid_df, test_df)"
      ],
      "metadata": {
        "id": "a4p-7Wzit3K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_length = len(test_df)\n",
        "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ],
      "metadata": {
        "id": "BImk13jGCOdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluasi lanjutan test_df"
      ],
      "metadata": {
        "id": "Jh-IrudywYZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "eotQrS4at31s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_dict = test_gen.class_indices\n",
        "classes = list(g_dict.keys())\n",
        "\n",
        "# Confusion matrix\n",
        "cmtrx = confusion_matrix(test_gen.classes, y_pred)\n",
        "plot_confusion_matrix(cm= cmtrx, classes= classes, title = 'Confusion Matrix')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "2hf5sE0GwcbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menyimpan Model VGG19(fine tuned)"
      ],
      "metadata": {
        "id": "iRIVTfUmIGgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model.input_names[0][:-6]\n",
        "subject = 'crocidolomia-pavonana-vgg-19'\n",
        "acc = test_score[1] * 100\n",
        "save_path = ''\n",
        "\n",
        "# Save model\n",
        "save_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\n",
        "model_save_loc = os.path.join(save_path, save_id)\n",
        "model.save(model_save_loc)\n",
        "print(f'model was saved as {model_save_loc}')\n",
        "\n",
        "# Save weights\n",
        "weight_save_id = str(f'{model_name}-{subject}-weights.h5')\n",
        "weights_save_loc = os.path.join(save_path, weight_save_id)\n",
        "model.save_weights(weights_save_loc)\n",
        "print(f'weights were saved as {weights_save_loc}')"
      ],
      "metadata": {
        "id": "lgKyB3p1weXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import saved model"
      ],
      "metadata": {
        "id": "rIqTqoZaIzMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/i-crocidolomia-pavonana-resnet-v2-50-94.20.h5'"
      ],
      "metadata": {
        "id": "Sy6qZolTIIRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "1T9Mbw4iI-NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_layers = [layer.name for layer in model_load.layers]"
      ],
      "metadata": {
        "id": "MsDvr67BJAy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "img_path = test_df.iloc[n,0]\n",
        "true_label = test_df.iloc[n,1]\n",
        "\n",
        "img = keras.preprocessing.image.load_img(img_path, target_size=(256, 256))\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "array = keras.preprocessing.image.img_to_array(img) / 255\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "array1 = np.expand_dims(array, axis=0)"
      ],
      "metadata": {
        "id": "W7dfeMk1JC8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1.shape"
      ],
      "metadata": {
        "id": "C5fgMLLXJGtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1[0][0][100]"
      ],
      "metadata": {
        "id": "XqelJROiJHPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = model_load.predict(array1)"
      ],
      "metadata": {
        "id": "jGtdmBz4JI0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes[np.argmax(hasil[0])])\n",
        "print(f\"True : {true_label}\")"
      ],
      "metadata": {
        "id": "mBAmfh5VJKUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat GRAD-CAM\n",
        "### Prediction and Bounding Box Function"
      ],
      "metadata": {
        "id": "WrpBjf4aJP19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_dict = test_gen.class_indices\n",
        "classes = list(g_dict.keys())"
      ],
      "metadata": {
        "id": "QRr5a8P9JQQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "dmHSDIUhJW0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test heatmap"
      ],
      "metadata": {
        "id": "dAP3mwwzJY1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_layers[-10:]"
      ],
      "metadata": {
        "id": "2meLtQEsJYIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19s last convolution layer\n",
        "last_conv_layer_name = model_layers[-8]\n",
        "last_conv_layer_name"
      ],
      "metadata": {
        "id": "bxTUsC_QJbsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print what the top predicted class is\n",
        "preds = model_load.predict(array1)\n",
        "# print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
        "print(preds)\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(array1, model_load, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k9s3ToG-JclH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_heatmap_and_predict(img_path, model, ground_truth_label):\n",
        "    # Prepare image\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=(256, 256))\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    img_array = np.expand_dims(array, axis=0) / 255\n",
        "        #img_array = preprocess_input(get_img_array(img_path, size=img_size)) # ISSUE\n",
        "    # Print what the top predicted class is\n",
        "    preds = model.predict(img_array)\n",
        "    print(preds)\n",
        "    predicted_label = classes[np.argmax(preds[0])]\n",
        "    # print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
        "    print(f\"Prediksi           : {predicted_label}\")\n",
        "    print(f\"Label Sesungguhnya : [{ground_truth_label}]\")\n",
        "\n",
        "    # Generate class activation heatmap\n",
        "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "    return heatmap, predicted_label"
      ],
      "metadata": {
        "id": "iJ3qaM9tJeDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.5):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    (superimposed_img.save(cam_path))\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(img_path))\n",
        "    display(Image(cam_path))\n",
        "\n",
        "    return '/content/'+ str(cam_path)"
      ],
      "metadata": {
        "id": "gTjlt6DqJfsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_cam_to_mask(img_path, cam_path):\n",
        "    # Read the images\n",
        "    img = cv2.imread(cam_path)\n",
        "    img2 = cv2.imread(img_path)\n",
        "\n",
        "    # Resizing the image\n",
        "    image = cv2.resize(img, (700, 600))\n",
        "    image2 = cv2.resize(img2, (700, 600))\n",
        "\n",
        "    # Convert Image to Image HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Defining lower and upper bound HSV values\n",
        "    lower = np.array([0, 100, 20])\n",
        "    upper = np.array([35, 255, 255])\n",
        "\n",
        "    # Defining mask for detecting color\n",
        "    mask = cv2.inRange(hsv, lower, upper)\n",
        "\n",
        "    # Bitwise-AND mask and original image\n",
        "    result = cv2.bitwise_and(image2,image2, mask= mask)\n",
        "\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig('heatmap_mask.jpg', dpi=300, bbox_inches='tight', pad_inches=0)\n",
        "    heatmap_mask_path = '/content/heatmap_mask.jpg'\n",
        "\n",
        "    return heatmap_mask_path"
      ],
      "metadata": {
        "id": "YIP6bguaJhLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_area(img_path, heatmap_mask_path, ground_truth_label, label, output_filename):\n",
        "    im = cv2.imread(heatmap_mask_path)\n",
        "    im_xray = cv2.imread(img_path)\n",
        "\n",
        "#     assert im is not None, \"file could not be read, check with os.path.exists()\"\n",
        "\n",
        "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    imgray = cv2.resize(imgray, (700, 600))\n",
        "    im2 = cv2.resize(im_xray, (700, 600))\n",
        "    # imgray2 = cv2.cvtColor(im_xray, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(imgray, 20, 255, 0)\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    result = cv2.drawContours(im2, contours, -1, (0,255,0), 3)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # save image\n",
        "    plt.axis('off')\n",
        "\n",
        "    prediction_text = f\"Ground Truth: {label}, prediction: [{ground_truth_label}]\"\n",
        "    plt.title(prediction_text, color= 'blue', fontsize= 12)\n",
        "\n",
        "    plt.savefig(output_filename, dpi=300, bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "opjc7vZZJyU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(test_data_index, output_filename='bounding_crocidolomia_pavonana'):\n",
        "    # image's path for prediction\n",
        "    test_pict = test_df.iloc[test_data_index,:]\n",
        "    img_path = test_pict.filepaths\n",
        "    output_file = output_filename + '.jpg'\n",
        "\n",
        "    # make prediction and heatmap\n",
        "    heatmap, predict_label = image_to_heatmap_and_predict(img_path = img_path, model = model_load, ground_truth_label = test_pict.labels)\n",
        "\n",
        "    # generate grad cam\n",
        "    grad_cam_path = save_and_display_gradcam(img_path, heatmap)\n",
        "\n",
        "\n",
        "    # make grad cam maks\n",
        "    heatmap_mask_path = grad_cam_to_mask(img_path = img_path, cam_path = grad_cam_path)\n",
        "\n",
        "    # draw bounding area\n",
        "    draw_bounding_area(img_path = img_path, heatmap_mask_path = heatmap_mask_path, ground_truth_label = test_pict.labels, label = predict_label, output_filename=output_file)\n"
      ],
      "metadata": {
        "id": "ZBRmOfY9JzX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(33)"
      ],
      "metadata": {
        "id": "FMt6XPLVJz7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(18)"
      ],
      "metadata": {
        "id": "X6qAU34_hwNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(0)"
      ],
      "metadata": {
        "id": "SGwtx3Ou9cz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(14)"
      ],
      "metadata": {
        "id": "ZKW5Q8v8Tpeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YqRcl75SZ92b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}